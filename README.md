# IndiBias: Measuring Social Biases in Language Models for the Indian Context

**IndiBias** is a benchmark dataset and framework designed to quantify social biases in Large Language Models (LLMs) specifically for the Indian socio-cultural context. Unlike Western-centric benchmarks, IndiBias captures nuances such as **Caste, Religion, Region, and Intersectionality** in both **English and Hindi**.

This repository contains the code for data filtering, preprocessing, score generation, and analysis as presented in the **IndiBias** paper.

## ðŸ“„ About the Paper
We introduce a dataset encompassing 7 bias dimensions (Gender, Religion, Caste, Age, Region, Physical Appearance, Occupation). We benchmark models like **mBERT, XLM-R, IndicBERT, and Muril** to measure their preference for stereotypical associations using masked token probabilities.

## ðŸ“‚ File Descriptions

The repository consists of the following 4 key scripts:

*   **`copy_of_crowspair_ver7_filtering.py`**
    *   **Purpose:** Filters existing datasets (like CrowS-Pairs and StereoSet) to retain only bias types relevant to India and translates valid sentences into Hindi using NLLB and Google Translate.

*   **`copy_of_crowspair_ver10_namereplace.py`**
    *   **Purpose:** Preprocesses the dataset by randomizing specific names (e.g., swapping "Rahul" with "Faisal") to ensure bias scores are based on identity groups rather than specific proper nouns.

*   **`crowspair_ver8_scoregeneration.py`**
    *   **Purpose:** The core evaluation script that calculates Pseudo-Log-Likelihood (PLL) scores using Masked Language Models (MLM) to measure how "surprised" a model is by stereotypical vs. anti-stereotypical sentences.

*   **`copy_of_crowspair_ver9_analysis.py`**
    *   **Purpose:** Processes the raw scores generated by the scoring script to compute the final "Bias Percentage" for each model and generates Kernel Density Estimation (KDE) plots.
